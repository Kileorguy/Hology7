{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import BatchNormalization,Conv2D,MaxPooling2D,Activation,Dropout,Lambda,Dense,Flatten, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "# from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "image_size = (224,224)\n",
    "def preProcess(img):\n",
    "    img = cv.resize(img, image_size, \n",
    "               interpolation = cv.INTER_LINEAR)\n",
    "    img = to_hsv(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def to_hsv(img):\n",
    "\n",
    "  hue_shift = 180  \n",
    "  saturation_scale = 2\n",
    "  value_scale = 5\n",
    "\n",
    "  # img[..., 0] = (img[..., 0] + hue_shift) % 180 \n",
    "  img[..., 1] = np.clip(img[..., 1] * saturation_scale, 0, 255)\n",
    "  img[..., 2] = np.clip(img[..., 2] * value_scale, 0, 255)\n",
    "  img[..., 2] = cv.equalizeHist(img[..., 2])\n",
    "\n",
    "  img = cv.cvtColor(img, cv.COLOR_HSV2BGR)\n",
    "  # img = cv.equalizeHist(img)\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './train/'\n",
    "test_dir = './test/'\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "\n",
    "train_data = []\n",
    "train_jenis = []\n",
    "train_warna =[]\n",
    "\n",
    "test_data = []\n",
    "test_ids = []\n",
    "\n",
    "\n",
    "for i in os.listdir(train_dir):\n",
    "    if(i is not None):\n",
    "        img = cv.imread(train_dir+i)\n",
    "        img = preProcess(img)\n",
    "\n",
    "        train_data.append(img)\n",
    "\n",
    "        cond = train_df['id'] == int(i[:-4])\n",
    "        idx = train_df.loc[cond].index[0]\n",
    "        train_jenis.append(train_df.iloc[idx]['jenis'])\n",
    "        train_warna.append(train_df.iloc[idx]['warna'])\n",
    "\n",
    "for i in os.listdir(test_dir):\n",
    "    if(i is not None):\n",
    "        img = cv.imread(test_dir+i)\n",
    "        img = preProcess(img)\n",
    "        test_data.append(img)\n",
    "        test_ids.append(i[:-4])\n",
    "\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(train_jenis))\n",
    "print(len(train_warna))\n",
    "\n",
    "xtrain_data, xval_data, ytrain_jenis, yval_jenis, ytrain_warna, yval_warna = train_test_split(\n",
    "    train_data, train_jenis, train_warna, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(len(test_data))\n",
    "print(len(test_ids))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img):\n",
    "    plt.imshow(cv.cvtColor(img,cv.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ColorNet(input, nb_class):\n",
    "    top_conv1 = Conv2D(filters=48,kernel_size=(11,11),strides=(4,4),\n",
    "                              input_shape=(224,224,3),activation='relu')(input)\n",
    "    top_conv1 = BatchNormalization()(top_conv1)\n",
    "    top_conv1 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_conv1)\n",
    "\n",
    "    # second top convolution layer\n",
    "    # split feature map by half\n",
    "    top_top_conv2 = Lambda(lambda x : x[:,:,:,:24])(top_conv1)\n",
    "    top_bot_conv2 = Lambda(lambda x : x[:,:,:,24:])(top_conv1)\n",
    "\n",
    "    top_top_conv2 = Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_top_conv2)\n",
    "    top_top_conv2 = BatchNormalization()(top_top_conv2)\n",
    "    top_top_conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_top_conv2)\n",
    "\n",
    "    top_bot_conv2 = Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_bot_conv2)\n",
    "    top_bot_conv2 = BatchNormalization()(top_bot_conv2)\n",
    "    top_bot_conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_bot_conv2)\n",
    "\n",
    "    # third top convolution layer\n",
    "    # concat 2 feature map\n",
    "    top_conv3 = Concatenate()([top_top_conv2,top_bot_conv2])\n",
    "    top_conv3 = Conv2D(filters=192,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_conv3)\n",
    "\n",
    "    # fourth top convolution layer\n",
    "    # split feature map by half\n",
    "    top_top_conv4 = Lambda(lambda x : x[:,:,:,:96])(top_conv3)\n",
    "    top_bot_conv4 = Lambda(lambda x : x[:,:,:,96:])(top_conv3)\n",
    "\n",
    "    top_top_conv4 = Conv2D(filters=96,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_top_conv4)\n",
    "    top_bot_conv4 = Conv2D(filters=96,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_bot_conv4)\n",
    "\n",
    "    # fifth top convolution layer\n",
    "    top_top_conv5 = Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_top_conv4)\n",
    "    top_top_conv5 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_top_conv5) \n",
    "\n",
    "    top_bot_conv5 = Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(top_bot_conv4)\n",
    "    top_bot_conv5 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(top_bot_conv5)\n",
    "\n",
    "    # ============================================= TOP BOTTOM ===================================================\n",
    "    # first bottom convolution layer\n",
    "    bottom_conv1 = Conv2D(filters=48,kernel_size=(11,11),strides=(4,4),\n",
    "                              input_shape=(224,224,3),activation='relu')(input)\n",
    "    bottom_conv1 = BatchNormalization()(bottom_conv1)\n",
    "    bottom_conv1 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_conv1)\n",
    "\n",
    "    # second bottom convolution layer\n",
    "    # split feature map by half\n",
    "    bottom_top_conv2 = Lambda(lambda x : x[:,:,:,:24])(bottom_conv1)\n",
    "    bottom_bot_conv2 = Lambda(lambda x : x[:,:,:,24:])(bottom_conv1)\n",
    "\n",
    "    bottom_top_conv2 = Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_top_conv2)\n",
    "    bottom_top_conv2 = BatchNormalization()(bottom_top_conv2)\n",
    "    bottom_top_conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_top_conv2)\n",
    "\n",
    "    bottom_bot_conv2 = Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_bot_conv2)\n",
    "    bottom_bot_conv2 = BatchNormalization()(bottom_bot_conv2)\n",
    "    bottom_bot_conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_bot_conv2)\n",
    "\n",
    "    # third bottom convolution layer\n",
    "    # concat 2 feature map\n",
    "    bottom_conv3 = Concatenate()([bottom_top_conv2,bottom_bot_conv2])\n",
    "    bottom_conv3 = Conv2D(filters=192,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_conv3)\n",
    "\n",
    "    # fourth bottom convolution layer\n",
    "    # split feature map by half\n",
    "    bottom_top_conv4 = Lambda(lambda x : x[:,:,:,:96])(bottom_conv3)\n",
    "    bottom_bot_conv4 = Lambda(lambda x : x[:,:,:,96:])(bottom_conv3)\n",
    "\n",
    "    bottom_top_conv4 = Conv2D(filters=96,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_top_conv4)\n",
    "    bottom_bot_conv4 = Conv2D(filters=96,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_bot_conv4)\n",
    "\n",
    "    # fifth bottom convolution layer\n",
    "    bottom_top_conv5 = Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_top_conv4)\n",
    "    bottom_top_conv5 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_top_conv5) \n",
    "\n",
    "    bottom_bot_conv5 = Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(bottom_bot_conv4)\n",
    "    bottom_bot_conv5 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(bottom_bot_conv5)\n",
    "\n",
    "    # ======================================== CONCATENATE TOP AND BOTTOM BRANCH =================================\n",
    "    conv_output = Concatenate()([top_top_conv5,top_bot_conv5,bottom_top_conv5,bottom_bot_conv5])\n",
    "\n",
    "    flatten = Flatten()(conv_output)\n",
    "\n",
    "    FC_1 = Dense(units=4096, activation='relu')(flatten)\n",
    "    FC_1 = Dropout(0.6)(FC_1)\n",
    "    FC_2 = Dense(units=4096, activation='relu')(FC_1)\n",
    "    FC_2 = Dropout(0.6)(FC_2)\n",
    "    output = Dense(units=nb_class)(FC_2)\n",
    "    output = Activation(\"softmax\", name=\"color_output\")(output)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_grayscale(x):\n",
    "    return tf.image.rgb_to_grayscale(x)\n",
    "\n",
    "def CategoryNet(input, nb_class):\n",
    "\n",
    "    x = Lambda(rgb_to_grayscale)(input)\n",
    "    x = Conv2D(filters=96, kernel_size=(11, 11), strides=4, padding='valid', activation='relu')(x)\n",
    "\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(5, 5), strides=(2,2), padding='valid')(x)\n",
    "\n",
    "    x = Conv2D(filters=256, kernel_size=(5, 5), strides=1, padding='valid', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2,2), padding='valid')(x)\n",
    "\n",
    "    x = Conv2D(filters=384, kernel_size=(3, 3), strides=1, padding='valid', activation='relu')(x)\n",
    "    x = Conv2D(filters=384, kernel_size=(3, 3), strides=1, padding='valid', activation='relu')(x)\n",
    "    x = Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='valid', activation='relu')(x)\n",
    "    # x = Conv2D(filters=256, kernel_size=(3, 3), strides=2, padding='valid', activation='relu')(x)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2,2), padding='valid')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "\n",
    "    x = Dense(nb_class, activation='softmax', name=\"category_output\")(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_warna_categorical = to_categorical(train_warna,num_classes=len(np.unique(train_warna)))\n",
    "train_jenis_categorical = to_categorical(train_jenis,num_classes=len(np.unique(train_jenis)))\n",
    "\n",
    "# xtrain_data, xval_data, ytrain_jenis, yval_jenis, ytrain_warna, yval_warna\n",
    "ytrain_jenis = to_categorical(ytrain_jenis,num_classes=len(np.unique(ytrain_jenis)))\n",
    "ytrain_warna = to_categorical(ytrain_warna,num_classes=len(np.unique(ytrain_warna)))\n",
    "yval_jenis = to_categorical(yval_jenis,num_classes=len(np.unique(yval_jenis)))\n",
    "yval_warna = to_categorical(yval_warna,num_classes=len(np.unique(yval_warna)))\n",
    "\n",
    "xtrain_data = np.array(xtrain_data)\n",
    "xval_data = np.array(xval_data)\n",
    "\n",
    "print(train_warna_categorical)\n",
    "print(ytrain_warna)\n",
    "\n",
    "\n",
    "inp = Input(input_shape)\n",
    "\n",
    "colorBranch = ColorNet(input=inp, nb_class=len(np.unique(train_warna)))\n",
    "categoryBranch = CategoryNet(input=inp, nb_class=len(np.unique(train_jenis)))\n",
    "model = Model(\n",
    "\t\t\tinputs=inp,\n",
    "\t\t\toutputs=[categoryBranch, colorBranch],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.0001)\n",
    "\n",
    "losses = {\n",
    "\t\"category_output\": \"categorical_crossentropy\",\n",
    "\t\"color_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {\"category_output\": 1.0, \"color_output\": 1.0}\n",
    "\n",
    "metrics = {\n",
    "    \"category_output\": [\"accuracy\"],\n",
    "    \"color_output\": [\"accuracy\"],\n",
    "}\n",
    "\n",
    "model.compile(optimizer=opt, loss=losses, loss_weights=lossWeights,\n",
    "\tmetrics=metrics)\n",
    "\n",
    "history = model.fit(xtrain_data,\n",
    "\t{\"category_output\": ytrain_jenis, \"color_output\": ytrain_warna},\n",
    "    validation_data=(xval_data,\n",
    "\t\t{\"category_output\": yval_jenis, \"color_output\": yval_warna}),\n",
    "    \n",
    "\tepochs=50,\n",
    "\tverbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(xtrain_data,\n",
    "    {\"category_output\": ytrain_jenis, \"color_output\": ytrain_warna})\n",
    "\n",
    "print(\"Loss and metrics for each output:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Test Loss:', score[0])  \n",
    "print('Category Output Loss:', score[1]) \n",
    "print('Color Output Loss:', score[2])\n",
    "print('Category Output Accuracy:', score[3])\n",
    "print('Color Output Accuracy:', score[4])\n",
    "totall = len(history.history['loss'])\n",
    "\n",
    "\n",
    "totall = len(history.history['loss'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(totall), history.history['loss'], label='Total Loss')\n",
    "plt.plot(range(totall), history.history['category_output_loss'], label='Category Loss')\n",
    "plt.plot(range(totall), history.history['color_output_loss'], label='Color Loss')\n",
    "\n",
    "\n",
    "plt.plot(range(totall), history.history['val_category_output_loss'], label='Val Category Loss', linestyle='--')\n",
    "plt.plot(range(totall), history.history['val_color_output_loss'], label='Val Color Loss', linestyle='--')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(totall), history.history['category_output_accuracy'], label='Category Accuracy') \n",
    "plt.plot(range(totall), history.history['color_output_accuracy'], label='Color Accuracy')\n",
    "\n",
    "plt.plot(range(totall), history.history['val_category_output_accuracy'], label='Val Category Accuracy', linestyle='--')\n",
    "plt.plot(range(totall), history.history['val_color_output_accuracy'], label='Val Color Accuracy', linestyle='--')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array(test_data)\n",
    "print(len(test_data))\n",
    "predict = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predict[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_jenis = predict[0]\n",
    "prediction_warna = predict[1]\n",
    "\n",
    "final_jenis = []\n",
    "final_warna = []\n",
    "\n",
    "for p_jenis, p_warna in zip(prediction_jenis,prediction_warna):\n",
    "    # print(id)\n",
    "    final_jenis.append(np.argmax(p_jenis))\n",
    "    final_warna.append(np.argmax(p_warna))\n",
    "    # print(\"============\")\n",
    "final = pd.DataFrame({'id':test_ids, 'jenis': final_jenis,'warna': final_warna})\n",
    "# display(final)\n",
    "final.to_csv('submission.csv', index=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
